<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Miguel Angel Bautista</title>

    <meta name="author" content="Miguel Angel Bautista">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Miguel Angel Bautista
                </p>
                <p>
		I'm a research scientist at <a href="https://machinelearning.apple.com/">Apple MLR</a> in San Francisco, where I lead a small team that focuses on generative modeling research.
		At Apple I've worked on research on generative modeling methodologies for images, video, 3D, graphs and scientific problems.
		I did my PhD at <a href="http://www.ub.edu/">University of Barcelona</a>, where I was advised by <a href="https://sergioescalera.com">Sergio Escalera</a>. I spent a big part of my PhD at <a href="https://www.cmu.edu">CMU</a> working with <a href="https://www.cs.cmu.edu/~ftorre/index.html">Fernando De la Torre</a> on matrix factorization methods. I did my postdoc training with <a href=https://ommer-lab.com/people/ommer/">Bj&oumlrn Ommer</a> working on unsupervised deep learning and generative models.

                </p>
                <p style="text-align:center">
                  <a href="mailto:miguelangelbautistamartin@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV-updated.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=ZrRs-qoAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/itsbautistam">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://bsky.app/profile/itsbautistam.bsky.social">Bluesky</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/profilepic.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profilepic.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research Interests</h2>
                <p>
                  I'm interested in scalable and efficient generative modeling approaches that make as little assumptions about data as possible. My long term goal is to unify training recipes and architectures across different data domains (image, text, 3D, graphs, video, etc.). My research style is to focus on simplifying overly complex pipelines and design decisions, and finding what are the key designs that makes things actually work.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
              <h2>Prospective Applicants</h2>
              <p>
               Im always on the look out for strong full time RS and PhD interns to join my team and work on generative models. If you think you can be a good fit please reach out via email and describe your biggest accomplishment.
              </p>
            </td>
          </tr>
        </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
            <html>
              <head>

              </head>
              <body>
               <table>
                <table style="width:100%;border:0;border-spacing:0 10px;border-collapse:separate;margin:auto;">
                  <tbody>
                    <!-- === STARFlow === -->
                    <tr onmouseout="pub_1_stop()" onmouseover="pub_1_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_1_image"><img src="images/starflow.png" width="160"/></div>
                          <img src="images/starflow.png" width="160"/>
                        </div>
                        <script>function pub_1_start(){document.getElementById('pub_1_image').style.opacity="1";}
                                function pub_1_stop(){document.getElementById('pub_1_image').style.opacity="0";}pub_1_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2506.06276"><span class="papertitle">STARFlow: Scaling Latent Normalizing Flows for High-resolution Image Synthesis</span></a><br/>
                        Gu, Jiatao&nbsp;… Bautista, Miguel Angel&nbsp;… Zhai, Shuangfei<br/><em>arXiv 2025</em><br/>
                        <a href="https://arxiv.org/abs/2506.06276">arXiv</a>
                        <p>Scales latent normalizing flows so they happily pump out crisp, megapixel images without breaking a sweat.</p>
                      </td>
                    </tr>
      

      

      
                    <!-- === INRFlow === -->
                    <tr onmouseout="pub_4_stop()" onmouseover="pub_4_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_4_image"><img src="images/inrflow.png" width="160"/></div>
                          <img src="images/inrflow.png" width="160"/>
                        </div>
                        <script>function pub_4_start(){document.getElementById('pub_4_image').style.opacity="1";}
                                function pub_4_stop(){document.getElementById('pub_4_image').style.opacity="0";}pub_4_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2412.03791"><span class="papertitle">INRFlow: Flow Matching for INRs in Ambient Space</span></a><br/>
                        Wang, Yuyang&nbsp;… Bautista, Miguel Angel<br/><em>ICML 2025</em><br/>
                        <a href="https://arxiv.org/abs/2412.03791">arXiv</a>
                        <p>Teaches implicit neural representations to flow-match in ambient space, making continuous signals play nice.</p>
                      </td>
                    </tr>
      
                    <!-- === Normalizing flows are capable === -->
                    <tr onmouseout="pub_5_stop()" onmouseover="pub_5_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_5_image"><img src="images/tarflow.png" width="160"/></div>
                          <img src="images/tarflow.png" width="160"/>
                        </div>
                        <script>function pub_5_start(){document.getElementById('pub_5_image').style.opacity="1";}
                                function pub_5_stop(){document.getElementById('pub_5_image').style.opacity="0";}pub_5_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2412.06329"><span class="papertitle">Normalizing Flows Are Capable Generative Models</span></a><br/>
                        Zhai, Shuangfei&nbsp;… Bautista, Miguel Angel&nbsp;… Susskind, Josh<br/><em>ICML 2025</em><br/>
                        <a href="https://arxiv.org/abs/2412.06329">arXiv</a>
                        <p>Dispels the myth that flows lag behind by proving they can hit diffusion-level quality.</p>
                      </td>
                    </tr>


                                        <!-- === World-consistent video diffusion === -->
                                        <tr onmouseout="pub_0_stop()" onmouseover="pub_0_start()">
                                          <td>
                                            <div class="one">
                                              <div class="two" id="pub_0_image"><img src="images/3ddiffpoint.png" width="160"/></div>
                                              <img src="images/3ddiffpoint.png" width="160"/>
                                            </div>
                                            <script>function pub_0_start(){document.getElementById('pub_0_image').style.opacity="1";}
                                                    function pub_0_stop(){document.getElementById('pub_0_image').style.opacity="0";}pub_0_stop();</script>
                                          </td>
                                          <td>
                                            <a href="https://arxiv.org/abs/2412.01821"><span class="papertitle">World-consistent Video Diffusion with Explicit 3-D Modeling</span></a><br/>
                                            Zhang, Qihang&nbsp;… Bautista, Miguel Angel&nbsp;… Gu, Jiatao<br/><em>CVPR 2025</em><br/>
                                            <a href="https://arxiv.org/abs/2412.01821">arXiv</a>
                                            <p>Knits diffusion with a global 3-D scene so every video frame keeps its bearings in the same universe.</p>
                                          </td>
                                        </tr>
                        


                                        <!-- === Scalable AR image models === -->
                                        <tr onmouseout="pub_2_stop()" onmouseover="pub_2_start()">
                                          <td>
                                            <div class="one">
                                              <div class="two" id="pub_2_image"><img src="images/aim.png" width="160"/></div>
                                              <img src="images/aim.png" width="160"/>
                                            </div>
                                            <script>function pub_2_start(){document.getElementById('pub_2_image').style.opacity="1";}
                                                    function pub_2_stop(){document.getElementById('pub_2_image').style.opacity="0";}pub_2_stop();</script>
                                          </td>
                                          <td>
                                            <a href="https://arxiv.org/abs/2401.08541"><span class="papertitle">Scalable Pre-training of Large Autoregressive Image Models</span></a><br/>
                                            El-Nouby, Alaaeldin&nbsp;… Bautista, Miguel Angel&nbsp;… Joulin, Armand<br/><em>ICML 2024</em><br/>
                                            <a href="https://arxiv.org/abs/2401.08541">arXiv</a>
                                            <p>Shows how to pre-train skyscraper-sized AR image models at you-won’t-believe-it scale and keep them stable.</p>
                                          </td>
                                        </tr>
      
                                        <!-- === Swallowing the Bitter Pill === -->
                                        <tr onmouseout="pub_12_stop()" onmouseover="pub_12_start()">
                                          <td>
                                            <div class="one">
                                              <div class="two" id="pub_12_image"><img src="images/mcf.png" width="160"/></div>
                                              <img src="images/mcf.png" width="160"/>
                                            </div>
                                            <script>function pub_12_start(){document.getElementById('pub_12_image').style.opacity="1";}
                                                    function pub_12_stop(){document.getElementById('pub_12_image').style.opacity="0";}pub_12_stop();</script>
                                          </td>
                                          <td>
                                            <a href="https://arxiv.org/abs/2311.17932"><span class="papertitle">Swallowing the Bitter Pill: Simplified Scalable Conformer Generation</span></a><br/>
                                            Wang, Yuyang … Bautista, Miguel Ángel<br/><em>ICML 2024</em><br/>
                                            <a href="https://arxiv.org/abs/2311.17932">arXiv</a>
                                            <p>Simplifies conformer sampling so chemists can spin up billions of candidate molecules before lunch.</p>
                                          </td>
                                        </tr>
                          

                    <!-- === 3-D Shape Tokenization === -->
                    <tr onmouseout="pub_6_stop()" onmouseover="pub_6_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_6_image"><img src="images/shapetokens.png" width="160"/></div>
                          <img src="images/shapetokens.png" width="160"/>
                        </div>
                        <script>function pub_6_start(){document.getElementById('pub_6_image').style.opacity="1";}
                                function pub_6_stop(){document.getElementById('pub_6_image').style.opacity="0";}pub_6_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2412.15618"><span class="papertitle">3-D Shape Tokenization</span></a><br/>
                        Chang, Jen-Hao Rick&nbsp;… Bautista, Miguel Angel&nbsp;… Tuzel, Oncel<br/><em>arXiv 2024</em><br/>
                        <a href="https://arxiv.org/abs/2412.15618">arXiv</a>
                        <p>Turns complex shapes into bite-sized tokens so transformers can snack on 3-D data.</p>
                      </td>
                    </tr>

                                        <!-- === CTRLorALTer === -->
                                        <tr onmouseout="pub_3_stop()" onmouseover="pub_3_start()">
                                          <td>
                                            <div class="one">
                                              <div class="two" id="pub_3_image"><img src="images/ctrlorlalter.png" width="160"/></div>
                                              <img src="images/ctrlorlalter.png" width="160"/>
                                            </div>
                                            <script>function pub_3_start(){document.getElementById('pub_3_image').style.opacity="1";}
                                                    function pub_3_stop(){document.getElementById('pub_3_image').style.opacity="0";}pub_3_stop();</script>
                                          </td>
                                          <td>
                                            <a href="https://arxiv.org/abs/2405.07913"><span class="papertitle">CTRLorALTer: Conditional LoRAdapter for Efficient 0-Shot Control&nbsp;and Altering of T2I Models</span></a><br/>
                                            Stracke, Nick&nbsp;… Bautista, Miguel Angel&nbsp;… Ommer, Björn<br/><em>ECCV 2024</em><br/>
                                            <a href="https://arxiv.org/abs/2405.07913">arXiv</a>
                                            <p>Drops a tiny LoRA-style adapter that lets you steer or remix any text-to-image model on the fly.</p>
                                          </td>
                                        </tr>


                                        <!-- === Manifold diffusion fields === -->
                                        <tr onmouseout="pub_8_stop()" onmouseover="pub_8_start()">
                                          <td>
                                            <div class="one">
                                              <div class="two" id="pub_8_image"><img src="images/mdf.png" width="160"/></div>
                                              <img src="images/mdf.png" width="160"/>
                                            </div>
                                            <script>function pub_8_start(){document.getElementById('pub_8_image').style.opacity="1";}
                                                    function pub_8_stop(){document.getElementById('pub_8_image').style.opacity="0";}pub_8_stop();</script>
                                          </td>
                                          <td>
                                            <a href="https://arxiv.org/abs/2305.15586"><span class="papertitle">Manifold Diffusion Fields </span></a><br/>
                                            Elhag, Ahmed A&nbsp;… Bautista, Miguel Angel<br/><em>ICLR 2024</em><br/>
                                            <a href="https://arxiv.org/abs/2305.15586">arXiv</a>
                                            <p>Generalises diffusion to live directly on manifolds, so everything stays on-surface where it belongs.</p>
                                          </td>
                                        </tr>
      
                    <!-- === Diffusion probabilistic fields === -->
                    <tr onmouseout="pub_7_stop()" onmouseover="pub_7_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_7_image"><img src="images/dpf.png" width="160"/></div>
                          <img src="images/dpf.png" width="160"/>
                        </div>
                        <script>function pub_7_start(){document.getElementById('pub_7_image').style.opacity="1";}
                                function pub_7_stop(){document.getElementById('pub_7_image').style.opacity="0";}pub_7_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2303.00165"><span class="papertitle">Diffusion Probabilistic Fields</span></a><br/>
                        Zhuang, Peiye&nbsp;… Bautista, Miguel Ángel<br/><em>ICLR 2023</em><br/>
                        <a href="https://arxiv.org/abs/2303.00165">arXiv</a>
                        <p>Extends diffusion to continuous fields, letting you sample functions instead of pixels.</p>
                      </td>
                    </tr>
      

      
                    <!-- === Value-function diffusion === -->
                    <tr onmouseout="pub_9_stop()" onmouseover="pub_9_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_9_image"><img src="images/rl" width="160"/></div>
                          <img src="images/rl.png" width="160"/>
                        </div>
                        <script>function pub_9_start(){document.getElementById('pub_9_image').style.opacity="1";}
                                function pub_9_stop(){document.getElementById('pub_9_image').style.opacity="0";}pub_9_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2306.07290"><span class="papertitle">Value-Function Estimation Using Conditional Diffusion Models for Control</span></a><br/>
                        Mazoure, Bogdan&nbsp;… Bautista, Miguel Angel… Susskind, Josh<br/><em>arXiv 2023</em><br/>
                        <a href="https://arxiv.org/abs/2306.07290">arXiv</a>
                        <p>Uses diffusion models to guess value functions that keep robots from face-planting.</p>
                      </td>
                    </tr>
      
                    <!-- === Is generalized dynamic NVS possible today? === -->
                    <tr onmouseout="pub_10_stop()" onmouseover="pub_10_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_10_image"><img src="images/viewsynthxiao.png" width="160"/></div>
                          <img src="images/viewsynthxiao.png" width="160"/>
                        </div>
                        <script>function pub_10_start(){document.getElementById('pub_10_image').style.opacity="1";}
                                function pub_10_stop(){document.getElementById('pub_10_image').style.opacity="0";}pub_10_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2310.08587"><span class="papertitle">Is Generalised Dynamic Novel View Synthesis from Monocular Videos Possible Today?</span></a><br/>
                        Zhao, Xiaoming&nbsp;… Bautista, MA&nbsp;… Schwing, Alexander G<br/><em>ICLR 2023</em><br/>
                        <a href="https://arxiv.org/abs/2310.08587">arXiv</a>
                        <p>Kicks the tyres on dynamic NeRFs and asks if one-camera view synthesis is truly ready for prime time.</p>
                      </td>
                    </tr>

                                        <!-- === f-DM === -->
                                        <tr onmouseout="pub_17_stop()" onmouseover="pub_17_start()">
                                          <td>
                                            <div class="one">
                                              <div class="two" id="pub_17_image"><img src="images/fdm.png" width="160"/></div>
                                              <img src="images/fdm.png" width="160"/>
                                            </div>
                                            <script>function pub_17_start(){document.getElementById('pub_17_image').style.opacity="1";}
                                                    function pub_17_stop(){document.getElementById('pub_17_image').style.opacity="0";}pub_17_stop();</script>
                                          </td>
                                          <td>
                                            <a href="https://arxiv.org/abs/2210.04955"><span class="papertitle">f-DM: A Multi-stage Diffusion Model via Progressive Signal Transformation</span></a><br/>
                                            Gu, Jiatao … Bautista, Miguel Angel&nbsp;… Susskind, Josh<br/><em>ICLR 2023</em><br/>
                                            <a href="https://arxiv.org/abs/2210.04955">arXiv</a>
                                            <p>Stacks diffusion stages so each cleans up the mess left by the previous one.</p>
                                          </td>
                                        </tr>
      
                    <!-- === Adaptivity & modularity === -->
                    <tr onmouseout="pub_11_stop()" onmouseover="pub_11_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_11_image"><img src="images/modularity.png" width="160"/></div>
                          <img src="images/modularity.png" width="160"/>
                        </div>
                        <script>function pub_11_start(){document.getElementById('pub_11_image').style.opacity="1";}
                                function pub_11_stop(){document.getElementById('pub_11_image').style.opacity="0";}pub_11_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2310.08866"><span class="papertitle">Adaptivity & Modularity for Efficient Generalisation over Task Complexity</span></a><br/>
                        Abnar, Samira … Bautista, Miguel Angel … Susskind, Josh<br/><em>arXiv 2023</em><br/>
                        <a href="https://arxiv.org/abs/2310.08866">arXiv</a>
                        <p>Builds adaptive modules that reshuffle themselves to tackle tasks from trivial to torturous.</p>
                      </td>
                    </tr>
      

                                       <!-- === Gaudi === -->
                                       <tr onmouseout="pub_16_stop()" onmouseover="pub_16_start()">
                                        <td>
                                          <div class="one">
                                            <div class="two" id="pub_16_image"><img src="images/gaudi.png" width="160"/></div>
                                            <img src="images/gaudi.png" width="160"/>
                                          </div>
                                          <script>function pub_16_start(){document.getElementById('pub_16_image').style.opacity="1";}
                                                  function pub_16_stop(){document.getElementById('pub_16_image').style.opacity="0";}pub_16_stop();</script>
                                        </td>
                                        <td>
                                          <a href="https://arxiv.org/abs/2207.13751"><span class="papertitle">Gaudi: A Neural Architect for Immersive 3-D Scene Generation</span></a><br/>
                                          Bautista, Miguel Angel … Toshev, Alexander&nbsp;… others<br/><em>NeurIPS 2023</em><br/>
                                          <a href="https://arxiv.org/abs/2207.13751">arXiv</a>
                                          <p>Lets a neural maestro draft entire 3-D worlds in one forward pass.</p>
                                        </td>
                                      </tr>

      
                    <!-- === Fast & explicit NVS === -->
                    <tr onmouseout="pub_14_stop()" onmouseover="pub_14_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_14_image"><img src="images/fenvs.png" width="160"/></div>
                          <img src="images/fenvs.png" width="160"/>
                        </div>
                        <script>function pub_14_start(){document.getElementById('pub_14_image').style.opacity="1";}
                                function pub_14_stop(){document.getElementById('pub_14_image').style.opacity="0";}pub_14_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2107.05775"><span class="papertitle">Fast and Explicit Neural View Synthesis</span></a><br/>
                        Guo, Pengsheng … Bautista, Miguel Angel&nbsp;… Shan, Qi<br/><em>WACV 2022</em><br/>
                        <a href="https://arxiv.org/abs/2107.05775">arXiv</a>
                        <p>Trades a bit of fancy math for a big speed boost in NeRF-style renderers.</p>
                      </td>
                    </tr>
      
                    <!-- === FvOR === -->
                    <tr onmouseout="pub_15_stop()" onmouseover="pub_15_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_15_image"><img src="images/fvor.png" width="160"/></div>
                          <img src="images/fvor.png" width="160"/>
                        </div>
                        <script>function pub_15_start(){document.getElementById('pub_15_image').style.opacity="1";}
                                function pub_15_stop(){document.getElementById('pub_15_image').style.opacity="0";}pub_15_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2205.07763"><span class="papertitle">FvOR: Robust Joint Shape & Pose Optimisation for Few-view Object Reconstruction</span></a><br/>
                        Yang, Zhenpei … Bautista, Miguel Angel&nbsp;… Huang, Qixing<br/><em>CVPR 2022</em><br/>
                        <a href="https://arxiv.org/abs/2205.07763">arXiv</a>
                        <p>Squeezes the most geometry out of a handful of photos by optimising pose and shape together.</p>
                      </td>
                    </tr>
      
 
      

      

      
                    <!-- === Unconstrained scene generation === -->
                    <tr onmouseout="pub_19_stop()" onmouseover="pub_19_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_19_image"><img src="images/gsn.png" width="160"/></div>
                          <img src="images/gsn.png" width="160"/>
                        </div>
                        <script>function pub_19_start(){document.getElementById('pub_19_image').style.opacity="1";}
                                function pub_19_stop(){document.getElementById('pub_19_image').style.opacity="0";}pub_19_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2104.00670"><span class="papertitle">Unconstrained Scene Generation with Locally Conditioned Radiance Fields</span></a><br/>
                        DeVries, Terrance … Bautista, Miguel Angel&nbsp;… Susskind, Joshua M<br/><em>ICCV 2021</em><br/>
                        <a href="https://arxiv.org/abs/2104.00670">arXiv</a>
                        <p>Generates scenes everywhere at once by letting every point consult its local pals.</p>
                      </td>
                    </tr>
      

      
                    <!-- === Hypersim === -->
                    <tr onmouseout="pub_21_stop()" onmouseover="pub_21_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_21_image"><img src="images/hypersim.png" width="160"/></div>
                          <img src="images/hypersim.png" width="160"/>
                        </div>
                        <script>function pub_21_start(){document.getElementById('pub_21_image').style.opacity="1";}
                                function pub_21_stop(){document.getElementById('pub_21_image').style.opacity="0";}pub_21_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2011.02523"><span class="papertitle">Hypersim: A Photorealistic Synthetic Dataset for Holistic Indoor Scene Understanding</span></a><br/>
                        Roberts, Mike … Bautista, Miguel Angel&nbsp;… Susskind, Joshua M<br/><em>ICCV 2021</em><br/>
                        <a href="https://arxiv.org/abs/2011.02523">arXiv</a>
                        <p>Drops a massive synthetic indoor dataset so models stop over-fitting IKEA.</p>
                      </td>
                    </tr>


                    <!-- === Equivariant neural rendering === -->
                    <tr onmouseout="pub_22_stop()" onmouseover="pub_22_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_22_image"><img src="images/enr.png" width="160"/></div>
                          <img src="images/enr.png" width="160"/>
                        </div>
                        <script>function pub_22_start(){document.getElementById('pub_22_image').style.opacity="1";}
                                function pub_22_stop(){document.getElementById('pub_22_image').style.opacity="0";}pub_22_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2006.07630"><span class="papertitle">Equivariant Neural Rendering</span></a><br/>
                        Dupont, Emilien … Bautista, Miguel Angel … Shan, Qi<br/><em>ICML 2020</em><br/>
                        <a href="https://arxiv.org/abs/2006.07630">arXiv</a>
                        <p>Bakes symmetry into NeRF so rotating the scene doesn’t scramble its predictions.</p>
                      </td>
                    </tr>


                                                            <!-- === Generalisation of 3-D reconstruction === -->
                                                            <tr onmouseout="pub_18_stop()" onmouseover="pub_18_start()">
                                                              <td>
                                                                <div class="one">
                                                                  <div class="two" id="pub_18_image"><img src="images/3d43d.png" width="160"/></div>
                                                                  <img src="images/3d43d.png" width="160"/>
                                                                </div>
                                                                <script>function pub_18_start(){document.getElementById('pub_18_image').style.opacity="1";}
                                                                        function pub_18_stop(){document.getElementById('pub_18_image').style.opacity="0";}pub_18_stop();</script>
                                                              </td>
                                                              <td>
                                                                <a href="https://arxiv.org/abs/2006.15427"><span class="papertitle">On the Generalisation of Learning-based 3-D Reconstruction</span></a><br/>
                                                                Bautista, Miguel Angel … Susskind, Joshua M<br/><em>WACV 2020</em><br/>
                                                                <a href="https://arxiv.org/abs/2006.15427">arXiv</a>
                                                                <p>Nails down why some recon models wobble on unseen objects—and how to toughen them up.</p>
                                                              </td>
                                                            </tr>
                          
      
                    <!-- === Set Distribution Networks === -->
                    <tr onmouseout="pub_23_stop()" onmouseover="pub_23_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_23_image"><img src="images/sdn.png" width="160"/></div>
                          <img src="images/sdn.png" width="160"/>
                        </div>
                        <script>function pub_23_start(){document.getElementById('pub_23_image').style.opacity="1";}
                                function pub_23_stop(){document.getElementById('pub_23_image').style.opacity="0";}pub_23_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/2006.10705"><span class="papertitle">Set Distribution Networks: A Generative Model for Sets of Images</span></a><br/>
                        Zhai, Shuangfei … Bautista, Miguel Angel&nbsp;… Susskind, Josh M<br/><em>arXiv 2020</em><br/>
                        <a href="https://arxiv.org/abs/2006.10705">arXiv</a>
                        <p> Learns to sample whole image sets, not just singles, so galleries come pre-curated.</p>
                      </td>
                    </tr>
      
                    <!-- === Adaptive loss alignment === -->
                    <tr onmouseout="pub_24_stop()" onmouseover="pub_24_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_24_image"><img src="images/adaptivelossalignment.png" width="160"/></div>
                          <img src="images/adaptivelossalignment.png" width="160"/>
                        </div>
                        <script>function pub_24_start(){document.getElementById('pub_24_image').style.opacity="1";}
                                function pub_24_stop(){document.getElementById('pub_24_image').style.opacity="0";}pub_24_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/1905.05895"><span class="papertitle">Addressing the Loss-Metric Mismatch with Adaptive Loss Alignment</span></a><br/>
                        Huang, Chen … Bautista, Miguel Angel&nbsp;… Susskind, Josh<br/><em>ICML 2019</em><br/>
                        <a href="https://arxiv.org/abs/1905.05895">arXiv</a>
                        <p>Aligns your training loss with evaluation metrics so your model stops chasing the wrong goal.</p>
                      </td>
                    </tr>
      
                    <!-- === Deep unsupervised visual similarities === -->
                    <tr onmouseout="pub_25_stop()" onmouseover="pub_25_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_25_image"><img src="images/unsuppose.png" width="160"/></div>
                          <img src="images/unsuppose.png" width="160"/>
                        </div>
                        <script>function pub_25_start(){document.getElementById('pub_25_image').style.opacity="1";}
                                function pub_25_stop(){document.getElementById('pub_25_image').style.opacity="0";}pub_25_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/1802.08562"><span class="papertitle">Deep Unsupervised Learning of Visual Similarities</span></a><br/>
                        Sanakoyeu, Artsiom … Bautista, Miguel A&nbsp;… Ommer, Björn<br/><em>Pattern Recognition 2018</em><br/>
                        <a href="https://arxiv.org/abs/1802.08562">arXiv</a>
                        <p>Figures out what looks alike without ever seeing a label.</p>
                      </td>
                    </tr>
      
                    <!-- === Beyond one-hot === -->
                    <tr onmouseout="pub_26_stop()" onmouseover="pub_26_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_26_image"><img src="images/beyondonehot.png" width="160"/></div>
                          <img src="images/beyondonehot.png" width="160"/>
                        </div>
                        <script>function pub_26_start(){document.getElementById('pub_26_image').style.opacity="1";}
                                function pub_26_stop(){document.getElementById('pub_26_image').style.opacity="0";}pub_26_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/1806.10805"><span class="papertitle">Beyond One-Hot Encoding: Lower-Dimensional Target Embedding</span></a><br/>
                        Rodríguez, Pau … Bautista, Miguel A … Escalera, Sergio<br/><em>CVIU 2018</em><br/>
                        <a href="https://arxiv.org/abs/1806.10805">arXiv</a>
                        <p>Compresses targets so classifiers stop wasting neurons on zeros.</p>
                      </td>
                    </tr>
      
                    <!-- === Deep unsupervised similarity using posets === -->
                    <tr onmouseout="pub_28_stop()" onmouseover="pub_28_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_28_image"><img src="images/posets.png" width="160"/></div>
                          <img src="images/posets.png" width="160"/>
                        </div>
                        <script>function pub_28_start(){document.getElementById('pub_28_image').style.opacity="1";}
                                function pub_28_stop(){document.getElementById('pub_28_image').style.opacity="0";}pub_28_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/1704.02268"><span class="papertitle">Deep Unsupervised Similarity Learning Using Partially Ordered Sets</span></a><br/>
                        Bautista, Miguel A … Ommer, Björn<br/><em>CVPR 2017</em><br/>
                        <a href="https://arxiv.org/abs/1704.02268">arXiv</a>
                        <p> Learns visual hierarchies by arranging images into gentle ranking chains.</p>
                      </td>
                    </tr>
      
                    <!-- === Unsupervised video understanding === -->
                    <tr onmouseout="pub_30_stop()" onmouseover="pub_30_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_30_image"><img src="images/timopaper.png" width="160"/></div>
                          <img src="images/timopaper.png" width="160"/>
                        </div>
                        <script>function pub_30_start(){document.getElementById('pub_30_image').style.opacity="1";}
                                function pub_30_stop(){document.getElementById('pub_30_image').style.opacity="0";}pub_30_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/1708.01191"><span class="papertitle">Unsupervised Video Understanding by Reconciliation of Posture Similarities</span></a><br/>
                        Milbich, Timo … Bautista, Miguel Angel&nbsp;… Ommer, Björn<br/><em>CVPR 2017</em><br/>
                        <a href="https://arxiv.org/abs/1708.01191">arXiv</a>
                        <p>Clusters video frames by matching body poses, turning chaos into choreography.</p>
                      </td>
                    </tr>

                          
                    <!-- === CliqueCNN === -->
                    <tr onmouseout="pub_32_stop()" onmouseover="pub_32_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_32_image"><img src="images/cliquecnn.png" width="160"/></div>
                          <img src="images/cliquecnn.png" width="160"/>
                        </div>
                        <script>function pub_32_start(){document.getElementById('pub_32_image').style.opacity="1";}
                                function pub_32_stop(){document.getElementById('pub_32_image').style.opacity="0";}pub_32_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/1608.08792"><span class="papertitle">CliqueCNN: Deep Unsupervised Exemplar Learning</span></a><br/>
                        Bautista, Miguel A&nbsp;… Ommer, Björn<br/><em>NeurIPS 2016</em><br/>
                        <a href="https://arxiv.org/abs/1608.08792">arXiv</a>
                        <p>Lets every image teach itself by forming little friendship cliques.</p>
                      </td>
                    </tr>
      
                    <!-- === Error-correcting factorization === -->
                    <tr onmouseout="pub_31_stop()" onmouseover="pub_31_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_31_image"><img src="images/ecf.png" width="160"/></div>
                          <img src="images/ecf.png" width="160"/>
                        </div>
                        <script>function pub_31_start(){document.getElementById('pub_31_image').style.opacity="1";}
                                function pub_31_stop(){document.getElementById('pub_31_image').style.opacity="0";}pub_31_stop();</script>
                      </td>
                      <td>
                        <a href="https://arxiv.org/abs/1502.07976"><span class="papertitle">Error-Correcting Factorization</span></a><br/>
                        Bautista, Miguel Angel … Escalera, Sergio<br/><em>IEEE TPAMI 2015</em><br/>
                        <a href="https://arxiv.org/abs/1502.07976">arXiv</a>
                        <p>Breaks matrices into factors that double as error-correcting codes.</p>
                      </td>
                    </tr>

      
      



                                        <!-- === ADHD gesture system === -->
                                        <tr onmouseout="pub_34_stop()" onmouseover="pub_34_start()">
                                          <td>
                                            <div class="one">
                                              <div class="two" id="pub_34_image"><img src="images/adhd.png" width="160"/></div>
                                              <img src="images/adhd.png" width="160"/>
                                            </div>
                                            <script>function pub_34_start(){document.getElementById('pub_34_image').style.opacity="1";}
                                                    function pub_34_stop(){document.getElementById('pub_34_image').style.opacity="0";}pub_34_stop();</script>
                                          </td>
                                          <td>
                                            <a href="https://arxiv.org/abs/1410.4485"><span class="papertitle">A Gesture Recognition System for Detecting Behavioral Patterns of ADHD</span></a><br/>
                                            Bautista Martín, Miguel Ángel … Escalera, Sergio<br/><em>IEEE Trans. Cybernetics 2014</em><br/>
                                            <a href="https://arxiv.org/abs/1410.4485">arXiv</a>
                                            <p>Uses body gestures to spot ADHD behaviour without sticking sensors on kids.</p>
                                          </td>
                                        </tr
      
      
                    <!-- === Prob-DTW + BoVDW === -->
                    <tr onmouseout="pub_40_stop()" onmouseover="pub_40_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_40_image"><img src="images/bowvdprobdtw.png" width="160"/></div>
                          <img src="images/bowvdprobdtw.png" width="160"/>
                        </div>
                        <script>function pub_40_start(){document.getElementById('pub_40_image').style.opacity="1";}
                                function pub_40_stop(){document.getElementById('pub_40_image').style.opacity="0";}pub_40_stop();</script>
                      </td>
                      <td>
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167865513003450"><span class="papertitle">Probability-based Dynamic Time Warping & Bag-of-Visual-and-Depth-Words for Gesture Recognition in RGB-D</span></a><br/>
                        Hernández-Vela, Antonio … Bautista, Miguel Angel… Angulo, Cecilio<br/><em>Pattern Recognition 2014</em><br/>
                        <p>Mixes time warping with 3-D bag-of-words to keep gesture detection in sync.</p>
                      </td>
                    </tr>
      
                    <!-- === HuPBA 8k+ === -->
                    <tr onmouseout="pub_41_stop()" onmouseover="pub_41_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_41_image"><img src="images/hupba8k.png" width="160"/></div>
                          <img src="images/hupba8k.png" width="160"/>
                        </div>
                        <script>function pub_41_start(){document.getElementById('pub_41_image').style.opacity="1";}
                                function pub_41_stop(){document.getElementById('pub_41_image').style.opacity="0";}pub_41_stop();</script>
                      </td>
                      <td>
                        <a href="https://pdf.sciencedirectassets.com/271597/1-s2.0-S0925231214X00263/1-s2.0-S0925231214012594/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEL3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQC%2Bqqzj5woBjffXNYat34eQe12OIKhAjIQpjKAitqy8VAIgA5%2B%2FitRC598KDVOgT1nyvbSXZ5BeljL3T4mF8ySK4dYquwUIpf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDBSs%2BDdWldFEOjVj7yqPBXuffRLayU8Z6a8QgFkY55QOi1HRpX%2BQ2L%2FBWgRBIcf0vQx%2B4sAYIZJdPAs2X6DfecBF%2FsOz1uv3pTyg3kPRz3NoDJun8hmgBjHNFo9T2PmbRPursz%2BQCTNoyozPCMC11ClEpyCwE%2BWeox3IpY%2F3CPfeDUheOGZbZUiSPA5WK0K938c6law7eNXeFRa%2BD38AsOPAmmp%2FejhmYkQGzGDChee7buKTM1Zq9dvbMMr7xcKKUmSC%2FcQvQsTURpln2qVGkmGawY%2F%2FHz1W32Y2%2F3c4ySlTfe1l%2FIHOcAlmlO6kOJeaMzAlQ7GW3KAHIiO%2Fgo6223Ky2lPYq3tjTvuYR8H0VCXfB%2FUqTU8C92ZTWOHZFsuAm3XaGCNsP01DTGlom%2Bx2lZh21Ucgb5SAUyITq3OIXHI69F3NasOdbpWBbDBhAuRKJba%2FVRQu2qlRcZhXQfveogA05vBHStm8rGEick8CGtNZRbm29Y8ILKCfKrKipefLO7CzRYpvzCXe5IOqDFh7vYKWBUysMcPnNO95c7VPqTRsYF7GjqyvewJHuxM0S7J7TZT9YPZPAZ9FGg94HyozuzE4iWJNv7GowxrhfTOXbChYgXm2cPvJNjF73bkmHl1xqenQGNw8D8zpL9tGOLS69jtZ1nM06di7%2FJV6SkMrjfwNKDGrEGYB6Q4bL5iiOBeCKaAToFOQypP2KRTey11oJvfwhCsXbBzbvuvEQiqBJrcWhDSuxHefHqfc5P%2FsrYXthoWY1H%2FE23m8A8MWMmW6%2Bh7i6f4jXO7Lo4mOZCvlvZuLNtlQVs75suKo%2F5I6OXT4p6FljtzXKB8Za7RYPaxUnuJauQ7B3hcql%2Fph9%2F8Pu%2FPst1YQpRgFP3AyeOoGmtcwjfvPwgY6sQGKmlxHog%2Fi5UiaeQ2nUDY9meOWJNuVOu463NlISL1vXmM59b3wes0p3JfkpcczmVTTIxoGcpA6RNTHZUCWHngFZNh%2BXc1m2KX8Wlg29j9Qrq%2FbS%2Fu1aAuIOk3ODIzqX6rrdlPIEjF2EquYEJN6yDKITDUWIoKKo%2B9V3AZVeAF9qM3qKedNMCNEa%2FFyRii3BCTxwI%2FsEcfpAGAXfvQDvf3RwrTQbLdlcy0y%2FI71GbszQvI%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250619T125004Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY5UOTMOJS%2F20250619%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=253404a11c8ceb1fb5ea6cb6f8c0f96d4048a388656c6d15575790bb5db5cdb0&hash=0b43370a9629398f5d31f34c72aa17aa28f4e3372e826029b83e08217ded5477&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0925231214012594&tid=spdf-b652d2b8-16fc-4294-9910-bd0ff9dd9db3&sid=25b8575992caa740e33af208d39ea29803e5gxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0a115851555d525858&rr=952326691ccf0312&cc=es"><span class="papertitle">HuPBA 8k+: Dataset & ECOC-GraphCut-based Segmentation of Human Limbs</span></a><br/>
                        Sanchez, Daniel … Bautista, Miguel Ángel … Escalera, Sergio<br/><em>Neurocomputing 2014</em><br/>
                        <p>Serves up 8 k limb annotations and a graph-cut method to slice them cleanly.</p>
                      </td>
                    </tr>
      
                    <!-- === ECOC-compliant GA (paper 1) === -->
                    <tr onmouseout="pub_42_stop()" onmouseover="pub_42_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_42_image"><img src="images/geneticecocpr.png" width="160"/></div>
                          <img src="images/geneticecocpr.png" width="160"/>
                        </div>
                        <script>function pub_42_start(){document.getElementById('pub_42_image').style.opacity="1";}
                                function pub_42_stop(){document.getElementById('pub_42_image').style.opacity="0";}pub_42_stop();</script>
                      </td>
                      <td>
                        <a href="https://openaccess.uoc.edu/server/api/core/bitstreams/f7630460-96e4-4709-ad7a-0633ea841026/content"><span class="papertitle">On the Design of an ECOC-Compliant Genetic Algorithm</span></a><br/>
                        Bautista Martín, Miguel Ángel … Pujol, Oriol<br/><em>Patter Recognition 2014</em><br/>
                        <p>Evolves error-correcting codes that keep classifiers honest.</p>
                      </td>
                    </tr>
      
      
                    <!-- === Prob-DTW for RGB-D === -->
                    <tr onmouseout="pub_45_stop()" onmouseover="pub_45_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_45_image"><img src="images/probdtw.png" width="160"/></div>
                          <img src="images/probdtw.png" width="160"/>
                        </div>
                        <script>function pub_45_start(){document.getElementById('pub_45_image').style.opacity="1";}
                                function pub_45_stop(){document.getElementById('pub_45_image').style.opacity="0";}pub_45_stop();</script>
                      </td>
                      <td>
                        <a href="https://www.maia.ub.es/~sergio/linked/icprdepthdtwgmm.pdf"><span class="papertitle">Probability-based Dynamic Time Warping for Gesture Recognition on RGB-D Data</span></a><br/>
                        Bautista, Miguel Angel … Escalera, Sergio<br/><em>ICPR 2014</em><br/>
                        <p>Speeds up DTW by sprinkling probability, making gesture matching less twitchy.</p>
                      </td>
                    </tr>

      
                    <!-- === BoVDW === -->
                    <tr onmouseout="pub_47_stop()" onmouseover="pub_47_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_47_image"><img src="images/bovdw.png" width="160"/></div>
                          <img src="images/bovdw.png" width="160"/>
                        </div>
                        <script>function pub_47_start(){document.getElementById('pub_47_image').style.opacity="1";}
                                function pub_47_stop(){document.getElementById('pub_47_image').style.opacity="0";}pub_47_stop();</script>
                      </td>
                      <td>
                        <a href="https://refbase.cvc.uab.es/files/HBP2012.pdf"><span class="papertitle">BoVDW: Bag-of-Visual-and-Depth-Words for Gesture Recognition</span></a><br/>
                        Hernández-Vela, Antonio … Bautista, Miguel Angel&nbsp;… Escalera, Sergio<br/><em>CVPR 2013 Workshop Faces and Gestures</em><br/>
                        <p>Combines 2-D and depth words so gestures pop out clearly.</p>
                      </td>
                    </tr>
      
                    <!-- === Minimal ECOC === -->
                    <tr onmouseout="pub_48_stop()" onmouseover="pub_48_start()">
                      <td>
                        <div class="one">
                          <div class="two" id="pub_48_image"><img src="images/minimal.png" width="160"/></div>
                          <img src="images/minimal.png" width="160"/>
                        </div>
                        <script>function pub_48_start(){document.getElementById('pub_48_image').style.opacity="1";}
                                function pub_48_stop(){document.getElementById('pub_48_image').style.opacity="0";}pub_48_stop();</script>
                      </td>
                      <td>
                        <a href="https://pdf.sciencedirectassets.com/271524/1-s2.0-S0167865512X00035/1-s2.0-S0167865511002960/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIEEIgGXlTw7jyvLMiO9gSzbbX%2FanLtk65tKuND%2F2%2BX3mAiAMWkMn%2FysCOmrQsb4kyRLu4Jk%2BXSCHQOglzz3MNiElESq8BQin%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIMr6GGdkCB5Si8kygTKpAFVlKu7rHXSSufgmVvRUrqJxYAUazoI8yzrT9Kofb2CRgKaU9tyayuPsopfHMT87B7rni9%2Fi8Zxisy4rgx7JDkIFA06V7aUqKIdGUibHSPDQ8Brekc3pqBwonIqdZs9v4jB2P7GhYXAxWeHy6jRWN5FeTi6McQZ7QPolq%2BrtHfJWPy%2B3RRg%2FiJVFCCzr1RyfXAYwmjy7%2F616sUQ5tcXf%2Fvv%2FOvBslLbh2rpvXgrgTHbE62%2Fve9FJ0ya6n6GF6Aj5z2Csl3XfjxxHYKbRPIeGrjhdKOjq%2FeinWapumQS%2BWQbQZN06Z8ZO42IoCL4kEhjm1HUQNfu4pznIDkbOmb9WQyM4mnJBQF4z%2BiWK4mIjBVwSAD2SS%2F2IciWzEYa9MlyzAds6y3EpQRcqgBvGFyD%2F%2BhpqwVj%2FFkv972NlwCT7Kj5iklCiC5Tvkn1d30YZWgHsyRS%2BcONBRgFBw9GDkl7O3%2BLZWtYkipOwW0yKk7RQdFmQlADt5e%2F4E%2FHw1DYmapJO59JMHfaunCWIocNdxUZFIK4C4njmR%2Fdz9ltb9EAEadAg%2BKB3%2BO%2BH0fiYBRFhK2ZiDyja%2FDWQFZZ%2FXkL2oUx3xH20QrE%2FDU0U1N2CFm7VvVzQMVNNzsqJL%2BTDFFtQtOYi9fhjGUGBJQBnIJRFfFlah4eQhtzOxELOAyjL41Dz%2BnfnDUqlsPgJgHRSstISVszKwqK2qOnmvAYKao5DWdLFsn2BvJvcndj3t6F7rZh8Dw9Mpx2d16%2FMVO2V28SRHH5HSvr0JK1qTywtcLcazML8Y7bjq4u2%2BrL84UmHbkIHZaDwIFB8Y546skZ44IM77NdM8s3fAHneabnWsvGE0GS7Rdv556ljE0%2B42yfmdrVQc3U%2BYwx7jQwgY6sgH66hOHM%2FYvC3H5V182o%2BQPYFCW2H6ra6WZc1JtCo4x%2BosAQpJc8w%2BZX7jTKg6uPBpZ8NeuLa2mXJhe5h9u6DjBS7j7os5fMgp3NGpd9nCsyYRq0LZj4Ni6uc4K%2FFf0r78QUTO2qT3S0RAI6Tu%2FqbshDlIOwrVWp9vJdGbHwrzMBoPwfonKKtGnGpFqyRVLYvUDoDuXEnhUp229u5HnBwixg33gZIBHVnPcGwQvbqBpVIH8&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250619T152145Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYXPN2B6L3%2F20250619%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=987370447ad8492d5ae08aa28c208e8e8a104adc284e31fccfb9c126c1d52032&hash=d775a5c20e1688104c0e327ba7ccb85ea7f926db13cf3385a748fe434bb81587&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0167865511002960&tid=spdf-def0e2d4-1288-4c59-a9af-347aca64ffdb&sid=25b8575992caa740e33af208d39ea29803e5gxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0a115851555a505a57&rr=952404997aa02183&cc=es"><span class="papertitle">Minimal Design of Error-Correcting Output Codes</span></a><br/>
                        Bautista, Miguel Ángel … Pujol, Oriol<br/><em>Pattern Recognition Letters 2012</em><br/>
                        <p>Shows you don’t need bloated codes to get robust multiclass classifiers.</p>
                      </td>
                    </tr>

    
               </table>
              </body>
             </html>
             